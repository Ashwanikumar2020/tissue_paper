{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "tissue_demo.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKq4BL6hp1f6",
        "colab_type": "text"
      },
      "source": [
        "## **Tissue Paper Detection, Masking and Wet-Area Percentage Calculation**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The following code adapts from the [Mask_RCNN](https://arxiv.org/abs/1703.06870) implementation from the Facebook AI Research Team (FAIR).\n",
        "\n",
        "*    Main source repository: https://github.com/matterport/Mask_RCNN\n",
        "*    Our implementation: https://github.com/rajat-roy/tissue_paper\n",
        "*    Read the documentation here: [pdf](https://github.com/Rajat-Roy/tissue_paper/blob/master/README.pdf) , \n",
        "[word](https://github.com/Rajat-Roy/tissue_paper/raw/master/Wet%20Area%20Detection%20Rajat.docx)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUWHbLtQXJ7V",
        "colab_type": "text"
      },
      "source": [
        "### **1. Import all the dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bW_9ouz4qSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "# Disable Tensorflow warnings\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# import inference code\n",
        "from tissue import Inference\n",
        "\n",
        "# Enable plotting in notebook\n",
        "%matplotlib inline\n",
        "clear_output() # clear the output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTWFdXm5QmTl",
        "colab_type": "text"
      },
      "source": [
        "### **2. Do some Inference and calculation**\n",
        "*   Change image_path to test another image, like `image_path = \"dataset/val/?.jpg\"`.\n",
        "*    (Optional) Upload images directly from local drive via upload option in files tab and set `image_path = \"?.jpg\"`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "BdFt6Uf14qSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up file paths\n",
        "image_path = \"dataset/val/105.jpg\" # Input Image path\n",
        "# image_path = \"6.jpg\"\n",
        "weights_path = \"mask_rcnn_tissue_0001.h5\" # pre-trained model weights path\n",
        "\n",
        "# Inference on new image\n",
        "result = Inference(weights_path, image_path)\n",
        "\n",
        "# show the results\n",
        "img = cv2.imread(image_path) # raw input image\n",
        "img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(result)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}